{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6eeb8bb57037413fa57be46238273d69":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12edb559e01d48eba41f31d5c50fd208","IPY_MODEL_b30d801656f34b1d9f66abdc8c8752ae","IPY_MODEL_cc59eb710e7f498aa9ca069e33f9329a"],"layout":"IPY_MODEL_0da0d050ed464d3f869ef9b3f394312f"}},"12edb559e01d48eba41f31d5c50fd208":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44b6590f5ea4455196dff329fd71af96","placeholder":"​","style":"IPY_MODEL_513a06baa6154824a053fdde16450377","value":"config.json: 100%"}},"b30d801656f34b1d9f66abdc8c8752ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_291643ea54f14ce18db9779c9e96ea7d","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4784029c44f14e488301fba56398ba5b","value":1208}},"cc59eb710e7f498aa9ca069e33f9329a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef2914dbe7ef454aae68fb3923f8efcb","placeholder":"​","style":"IPY_MODEL_40cf8d6b3dd2430cb0476a2c988cdcfb","value":" 1.21k/1.21k [00:00&lt;00:00, 115kB/s]"}},"0da0d050ed464d3f869ef9b3f394312f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44b6590f5ea4455196dff329fd71af96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"513a06baa6154824a053fdde16450377":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"291643ea54f14ce18db9779c9e96ea7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4784029c44f14e488301fba56398ba5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef2914dbe7ef454aae68fb3923f8efcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40cf8d6b3dd2430cb0476a2c988cdcfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e23e23ed601f4883b16a76e5492f851b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_100b1efc353945c6a453cfb37881e908","IPY_MODEL_84061250061f49bfacac8bf477468579","IPY_MODEL_76a4835a35f1422a8d04cb57ae6267c0"],"layout":"IPY_MODEL_74fadc62b2a146a8bdb556acdebd9017"}},"100b1efc353945c6a453cfb37881e908":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_985a68582c04495dbb9cc5c987923264","placeholder":"​","style":"IPY_MODEL_89ef26d347e8414cbb35e50d42134659","value":"spiece.model: 100%"}},"84061250061f49bfacac8bf477468579":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a55c3aea37524f329cf11276ebad7392","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4351463426cf423dba22402424775586","value":791656}},"76a4835a35f1422a8d04cb57ae6267c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5846ff1651a04560b55c2be0051c9296","placeholder":"​","style":"IPY_MODEL_23120697f1dc4823ada9b188d639ff67","value":" 792k/792k [00:00&lt;00:00, 10.9MB/s]"}},"74fadc62b2a146a8bdb556acdebd9017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"985a68582c04495dbb9cc5c987923264":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89ef26d347e8414cbb35e50d42134659":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a55c3aea37524f329cf11276ebad7392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4351463426cf423dba22402424775586":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5846ff1651a04560b55c2be0051c9296":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23120697f1dc4823ada9b188d639ff67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f1f23703b2c43ad8752c7d71cd1ca6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a098666ed084ea9a06fc84721c2f317","IPY_MODEL_279f1ecfeee74642aeb0061e1416fccb","IPY_MODEL_5e98b68c61ea4eda89054c8d08bdb46c"],"layout":"IPY_MODEL_848f0e70210d4974b049dd243ac48080"}},"7a098666ed084ea9a06fc84721c2f317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec7f12b22b6345d899ab37a0a109cc44","placeholder":"​","style":"IPY_MODEL_d1f7b13ef0b446cbb499aa205cf9ad0e","value":"tokenizer.json: 100%"}},"279f1ecfeee74642aeb0061e1416fccb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69ee8d425bc1469cb0f91bacbec3f349","max":1389353,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae376c5f0ec94c529652b6e9b9b3f70e","value":1389353}},"5e98b68c61ea4eda89054c8d08bdb46c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a69d689c4be4373aea2eafebf44fbef","placeholder":"​","style":"IPY_MODEL_19f0c378487042b1bed1d60a0579fc18","value":" 1.39M/1.39M [00:00&lt;00:00, 19.1MB/s]"}},"848f0e70210d4974b049dd243ac48080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec7f12b22b6345d899ab37a0a109cc44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f7b13ef0b446cbb499aa205cf9ad0e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69ee8d425bc1469cb0f91bacbec3f349":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae376c5f0ec94c529652b6e9b9b3f70e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a69d689c4be4373aea2eafebf44fbef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19f0c378487042b1bed1d60a0579fc18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f43c2282982b4fb1b77835b4aedd0d6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f64ad0f2433f4bbf9618053eac64244c","IPY_MODEL_e8253bd633e04823aeccc64896caa32c","IPY_MODEL_cc0307043d2246d2abe7c6642ed895c4"],"layout":"IPY_MODEL_9daa8044a50942f495c81bf71cf94111"}},"f64ad0f2433f4bbf9618053eac64244c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3824ff21f9bf4202b378eb935c1bf989","placeholder":"​","style":"IPY_MODEL_05737b613c7f4d2ab2715b68b62beb6f","value":"model.safetensors: 100%"}},"e8253bd633e04823aeccc64896caa32c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3df0d4a331643d5a6be53916799154a","max":891646390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df91a8cd3c4942e78a51742e7efc8173","value":891646390}},"cc0307043d2246d2abe7c6642ed895c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f891d63a0f424906889ac95573635748","placeholder":"​","style":"IPY_MODEL_e674330f585f48ab94f9a7076daf889c","value":" 892M/892M [00:14&lt;00:00, 83.2MB/s]"}},"9daa8044a50942f495c81bf71cf94111":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3824ff21f9bf4202b378eb935c1bf989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05737b613c7f4d2ab2715b68b62beb6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3df0d4a331643d5a6be53916799154a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df91a8cd3c4942e78a51742e7efc8173":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f891d63a0f424906889ac95573635748":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e674330f585f48ab94f9a7076daf889c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cae174c65b8497fa2b81db5e0ab1538":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_746304975ba44121ad515e7b31a30735","IPY_MODEL_b8fc7a37051249808cf032843e80fe3e","IPY_MODEL_3eff6d87d3b34781afb29511c2c9ba8c"],"layout":"IPY_MODEL_0712b000505a44c982b56e99c9fe44ab"}},"746304975ba44121ad515e7b31a30735":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ccee3724b1d4f36a5a8166d342f6368","placeholder":"​","style":"IPY_MODEL_58c5ffc0d53b44fbb8c9ba934091150d","value":"generation_config.json: 100%"}},"b8fc7a37051249808cf032843e80fe3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6150cce7cf40424b8a12b3de5f33f2fa","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_991ada0373c44389a5c6383a2c5e3108","value":147}},"3eff6d87d3b34781afb29511c2c9ba8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4300c3ab83ed4e919f9cd11608677e6a","placeholder":"​","style":"IPY_MODEL_7f3b63c9e3d34173a99454496e6d4624","value":" 147/147 [00:00&lt;00:00, 2.92kB/s]"}},"0712b000505a44c982b56e99c9fe44ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ccee3724b1d4f36a5a8166d342f6368":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c5ffc0d53b44fbb8c9ba934091150d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6150cce7cf40424b8a12b3de5f33f2fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"991ada0373c44389a5c6383a2c5e3108":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4300c3ab83ed4e919f9cd11608677e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f3b63c9e3d34173a99454496e6d4624":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Chunking Strategies**\n","\n","In Retrieval-Augmented Generation (RAG), chunking refers to the process of dividing a large corpus of text into smaller, more manageable units (chunks), which can be used for efficient retrieval and processing. The primary goal of chunking is to break down text into smaller pieces that maintain meaningful content while reducing computational complexity during retrieval.\n","\n","1. Fixed Size Chunkng\n","2. Sentence Based Chunking\n","3. Document Based Chunking\n","4. Semantic Chunking\n","5. Overalapping Chunking\n","6. Recursive Chunking\n","7. Agentic Chunking\n","8. Content-Aware Chunking\n","9. Token Based Chunking\n","10. Topic Based Chunking\n","11. Keyword Based Chunking"],"metadata":{"id":"AYCnCvx-PUt8"}},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-MrYGjK3fcj1","executionInfo":{"status":"ok","timestamp":1754905080208,"user_tz":-330,"elapsed":13100,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"e78ceff8-4d92-4753-fc72-0491a52a584a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_community\n","  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.72)\n","Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.27)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.42)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.12)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n","  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.1)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n","  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n","Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n","Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain_community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"]}]},{"cell_type":"code","source":["!pip install chromadb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"bofOp7plf4aK","executionInfo":{"status":"ok","timestamp":1754905176262,"user_tz":-330,"elapsed":19500,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"51898200-4309-44dd-8f7b-225725e71fdc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting chromadb\n","  Downloading chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.3.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n","Collecting pybase64>=1.4.1 (from chromadb)\n","  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n","Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n","Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n","  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.1)\n","Collecting onnxruntime>=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.4)\n","Collecting pypika>=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n","Collecting overrides>=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.74.0)\n","Collecting bcrypt>=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n","Collecting kubernetes>=28.1.0 (from chromadb)\n","  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n","Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb)\n","  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.1)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n","Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.25.0)\n","Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n","  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n","Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n","Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n","  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n","  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n","Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n","  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.7)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n","Downloading chromadb-1.0.16-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=abf9716e00f844f51479e8d9c18a6868887854ef7bcc8fca8c5097d6c30c3164\n","  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n","Successfully built pypika\n","Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n","Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.16 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"]}]},{"cell_type":"markdown","source":["# **Smaller Chunks vs Larger Chunks**\n","\n","RecursiveCharacterTextSplitter doesn’t just count characters and cut.\n","\n","It tries to break the text at logical boundaries (like sentences, paragraphs, or spaces) based on a list of separators:\n","\n","It will only go down to raw character-level splitting if no larger separator fits.\n","\n","However, because splitting is based on tokens/words, overlap is not always obvious — especially if the chunk boundary doesn’t land inside a word."],"metadata":{"id":"N6s1BlgdPPZm"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import Chroma\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","# Sample document (larger for better testing)\n","document = \"\"\"\n","Elon Musk is the CEO of Tesla. Tesla's mission is to accelerate the world's transition to sustainable energy.\n","Tesla manufactures electric vehicles (EVs), battery energy storage, solar panels, and related products. SpaceX, another company led by Musk,\n","aims to make space travel accessible to humanity by developing reusable rockets.\n","Musk has also co-founded Neuralink, which focuses on connecting the human brain to computers using advanced neural interfaces.\n","Recently, Musk has expressed his concerns about artificial intelligence, advocating for regulation to prevent potential harm.\n","Musk believes that governments should play an active role in ensuring the safe development of AI technologies.\n","His innovative ventures span automotive, space exploration, energy, AI, and neuroscience, making him a pivotal figure in modern technology.\n","\"\"\"\n","\n","# Small chunk size\n","small_splitter = RecursiveCharacterTextSplitter(chunk_size=20, chunk_overlap=2)  # separators=[\"\"] - to see the exact split and overlap\n","small_chunks = small_splitter.split_text(document)\n","print(\"Smaller Chunks -\")\n","print(small_chunks)\n","# Large chunk size\n","large_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=10)\n","large_chunks = large_splitter.split_text(document)\n","print(\"Larger Chunks -\")\n","print(large_chunks)\n","# Initialize embedding model\n","embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# Create vector stores\n","small_vector_store = Chroma.from_texts(small_chunks, embedding_model)\n","large_vector_store = Chroma.from_texts(large_chunks, embedding_model)\n","\n","# Semantic query\n","query = \"What are Musk's views on artificial intelligence and government regulations?\"\n","\n","# Perform search\n","small_results = small_vector_store.similarity_search(query, k=1)\n","large_results = large_vector_store.similarity_search(query, k=1)\n","\n","# Display results\n","print(\"-----------------------------------\")\n","print(\"Results\")\n","print(\"-----------------------------------\")\n","print(\"Small Chunk Results:\", small_results)\n","print(\"Large Chunk Results:\", large_results)"],"metadata":{"id":"jXR04b_APS0t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754905625693,"user_tz":-330,"elapsed":1661,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"cc250fc0-7746-4ecb-ca6b-0778d281325a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Smaller Chunks -\n","['Elon Musk is the', 'CEO of Tesla.', \"Tesla's mission is\", 'to accelerate the', \"world's transition\", 'to sustainable', 'energy.', 'Tesla manufactures', 'electric vehicles', '(EVs), battery', 'energy storage,', 'solar panels, and', 'related products.', 'SpaceX, another', 'company led by', 'Musk,', 'aims to make space', 'travel accessible', 'to humanity by', 'developing reusable', 'rockets.', 'Musk has also', 'co-founded', 'Neuralink, which', 'focuses on', 'connecting the', 'human brain to', 'computers using', 'advanced neural', 'interfaces.', 'Recently, Musk has', 'expressed his', 'concerns about', 'artificial', 'intelligence,', 'advocating for', 'regulation to', 'prevent potential', 'harm.', 'Musk believes that', 'governments should', 'play an active role', 'in ensuring the', 'safe development of', 'AI technologies.', 'His innovative', 'ventures span', 'automotive, space', 'exploration,', 'energy, AI, and', 'neuroscience,', 'making him a', 'a pivotal figure in', 'modern technology.']\n","Larger Chunks -\n","[\"Elon Musk is the CEO of Tesla. Tesla's mission is to accelerate the world's transition to sustainable energy.\", 'Tesla manufactures electric vehicles (EVs), battery energy storage, solar panels, and related products. SpaceX, another company led by Musk,', 'aims to make space travel accessible to humanity by developing reusable rockets.', 'Musk has also co-founded Neuralink, which focuses on connecting the human brain to computers using advanced neural interfaces.', 'Recently, Musk has expressed his concerns about artificial intelligence, advocating for regulation to prevent potential harm.', 'Musk believes that governments should play an active role in ensuring the safe development of AI technologies.', 'His innovative ventures span automotive, space exploration, energy, AI, and neuroscience, making him a pivotal figure in modern technology.']\n","-----------------------------------\n","Results\n","-----------------------------------\n","Small Chunk Results: [Document(metadata={}, page_content='Recently, Musk has expressed his concerns about artificial intelligence, advocating for regulation to prevent potential harm.')]\n","Large Chunk Results: [Document(metadata={}, page_content='Recently, Musk has expressed his concerns about artificial intelligence, advocating for regulation to prevent potential harm.')]\n"]}]},{"cell_type":"markdown","source":["### **1. Fixed-size Chunking (Sliding Window)**\n","\n","**What It Is:**\n","\n","Fixed-size chunking divides the text into fixed-length pieces or windows. This is done by splitting the text into chunks of a predetermined size (e.g., 512 tokens). This strategy is simple but can be inefficient for longer texts, especially if chunks cut across meaningful sections (like sentences).\n","\n","**Use Case:**\n","\n","Best for datasets where text length is fairly uniform or where processing uniform chunks is necessary."],"metadata":{"id":"QdmbSAatPXY8"}},{"cell_type":"code","source":["# Example of Fixed-size chunking using a sliding window\n","\n","def fixed_size_chunk(text, chunk_size=512):\n","    # Split text into words and chunk them into fixed-size parts\n","    words = text.split()\n","    chunks = [words[i:i + chunk_size] for i in range(0, len(words), chunk_size)]\n","    return [' '.join(chunk) for chunk in chunks]\n","\n","# Example text (typically a long document)\n","text = \"This is a very long text that should be chunked into smaller pieces for efficient processing.\"\n","\n","# Chunk into 5 words per chunk\n","chunks = fixed_size_chunk(text, chunk_size=5)\n","\n","# Display the chunks\n","for i, chunk in enumerate(chunks):\n","    print(f\"Chunk {i + 1}: {chunk}\")"],"metadata":{"id":"PP-TWjCtPVD2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754905739337,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"03a3d400-2a15-4de2-d61f-afb767884b67"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunk 1: This is a very long\n","Chunk 2: text that should be chunked\n","Chunk 3: into smaller pieces for efficient\n","Chunk 4: processing.\n"]}]},{"cell_type":"markdown","source":["### **2. Sentence-based Chunking**\n","\n","**What It Is:**\n","\n","Sentence-based chunking divides the text into individual sentences, treating each as a chunk. This is useful when working with structured text or datasets where each sentence contains meaningful information and needs to be processed independently.\n","\n","**Use Case:**\n","\n","Ideal for processing formal documents (e.g., research papers, news articles) where individual sentences convey significant meaning."],"metadata":{"id":"E_D-aBNdPbFP"}},{"cell_type":"code","source":["from nltk.tokenize import sent_tokenize\n","import nltk\n","nltk.download('punkt_tab')\n","\n","# Example text (typically a paragraph)\n","text = \"This is a sentence. Here is another one. And a third one.\"\n","\n","# Chunk text into sentences\n","chunks = sent_tokenize(text)\n","\n","# Display the chunks\n","for i, chunk in enumerate(chunks):\n","    print(f\"Sentence {i + 1}: {chunk}\")"],"metadata":{"id":"WuFljAqYPcOV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754905749604,"user_tz":-330,"elapsed":2309,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"9516e009-5d7d-475e-94dd-7388643c1f38"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Sentence 1: This is a sentence.\n","Sentence 2: Here is another one.\n","Sentence 3: And a third one.\n"]}]},{"cell_type":"markdown","source":["## **3. Document-based Chunking**\n","\n","**What It Is:**\n","\n","Document-based chunking involves treating each document or major section of text as a chunk. This approach is used when the corpus consists of multiple documents that need to be retrieved independently.\n","\n","**Use Case:**\n","\n","Useful when the corpus is already organized into meaningful documents, such as articles, reports, or books.\n","LlamaIndex (formerly GPT Index) has a built-in feature that can identify document boundaries."],"metadata":{"id":"3Q-FZqh5PexJ"}},{"cell_type":"code","source":["!pip install pypdf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"sSrUP2vmi3iE","executionInfo":{"status":"ok","timestamp":1754905948755,"user_tz":-330,"elapsed":10214,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"6455be5b-da31-441a-f45a-1261ece3e4fc"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pypdf\n","  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n","Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m307.2/313.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdf\n","Successfully installed pypdf-5.9.0\n"]}]},{"cell_type":"code","source":["from langchain.document_loaders import PyPDFLoader\n","\n","pdf_loader = PyPDFLoader(\"/content/neural_network.pdf\")\n","\n","# Load the PDF into documents\n","documents = pdf_loader.load()\n","\n","# Display the documents to check their structure\n","for i, doc in enumerate(documents[:3]):  # Display first 3 chunks for preview\n","    print(f\"Document {i + 1} Content:\")\n","    print(doc.page_content[:1000])  # Preview first 500 characters\n","    print(\"\\n\")"],"metadata":{"id":"oVdlPQfYPel9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754906092427,"user_tz":-330,"elapsed":17892,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"e828cb16-324b-4565-e1aa-ed5562229b16"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Document 1 Content:\n","Neural Networks and Deep Learning\n","Michael Nielsen\n","The original online book can be found at\n","http://neuralnetworksanddeeplearning.com\n","\n","\n","Document 2 Content:\n","\n","\n","\n","Document 3 Content:\n","i\n","Contents\n","What this book is about iii\n","On the exercises and problems v\n","1 Using neural nets to recognize handwritten digits 1\n","1.1 Perceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n","1.2 Sigmoid neurons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n","1.3 The architecture of neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n","1.4 A simple network to classify handwritten digits . . . . . . . . . . . . . . . . . . . 12\n","1.5 Learning with gradient descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n","1.6 Implementing our network to classify digits . . . . . . . . . . . . . . . . . . . . . 24\n","1.7 Toward deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n","2 How the backpropagation algorithm works 39\n","2.1 Warm up: a fast matrix-based approach to computing the output from a neural\n","network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","\n","\n"]}]},{"cell_type":"markdown","source":["## **4. Semantic-based Chunking (Dynamic Chunking)**\n","\n","**What It Is:**\n","\n","Semantic-based chunking involves splitting text into chunks based on the meaning of the content rather than fixed length or sentence boundaries. The idea is to group related information, which may vary in length, into semantic units. This is often done using NLP techniques, such as sentence embeddings or document clustering, to identify the most relevant sections for each chunk.\n","\n","**Use Case:**\n","\n","Best for use in situations where meaningful semantic units (e.g., paragraphs, topics) should be grouped together regardless of the chunk size. This is useful for document summarization, knowledge extraction, and other advanced NLP tasks."],"metadata":{"id":"NaECqcm7Phm7"}},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","from sklearn.cluster import KMeans\n","import numpy as np\n","\n","# Initialize a model for sentence embeddings\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","# Example text (to simulate chunking)\n","sentences = [\n","    \"Astronauts are sent to space.\",\n","    \"The Martian is about survival on Mars.\",\n","    \"Interstellar deals with space exploration.\",\n","    \"Space travel involves many challenges.\"\n","]\n","\n","# Create embeddings for each sentence\n","embeddings = model.encode(sentences)\n","\n","# Use clustering to group semantically similar sentences\n","kmeans = KMeans(n_clusters=2, random_state=0)\n","labels = kmeans.fit_predict(embeddings)\n","\n","# Group sentences by their cluster label\n","chunks = {}\n","for i, label in enumerate(labels):\n","    if label not in chunks:\n","        chunks[label] = []\n","    chunks[label].append(sentences[i])\n","\n","# Display semantic chunks\n","for label, chunk in chunks.items():\n","    print(f\"Semantic Chunk {label + 1}: {', '.join(chunk)}\")"],"metadata":{"id":"igcnQeDWPjZG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754906117637,"user_tz":-330,"elapsed":1860,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"088776eb-383b-4b5c-ea92-4c9fc86d8d3d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic Chunk 1: Astronauts are sent to space., Interstellar deals with space exploration., Space travel involves many challenges.\n","Semantic Chunk 2: The Martian is about survival on Mars.\n"]}]},{"cell_type":"markdown","source":["## **5. Overlapping Chunking**\n","\n","**What It Is:**\n","\n","Overlapping chunking involves creating chunks that overlap with each other. For example, one chunk might contain the last few words of the previous chunk. This strategy is used to preserve context between chunks and ensure that no information is lost when dividing long texts.\n","\n","**Use Case:**\n","\n","Useful when context between sentences is important, such as for tasks like machine translation, summarization, or question-answering where the meaning of adjacent chunks is highly dependent on each other."],"metadata":{"id":"11ctVCsjPlf0"}},{"cell_type":"code","source":["def overlapping_chunk(text, chunk_size=5, overlap=2):\n","    words = text.split()\n","    chunks = []\n","    for i in range(0, len(words), chunk_size - overlap):\n","        chunk = words[i:i + chunk_size]\n","        chunks.append(' '.join(chunk))\n","    return chunks\n","\n","# Example text\n","text = \"This is an example of overlapping chunking to maintain context between chunks.\"\n","\n","# Chunk into overlapping pieces with 5 words per chunk and 2-word overlap\n","chunks = overlapping_chunk(text, chunk_size=5, overlap=2)\n","\n","# Display the chunks\n","for i, chunk in enumerate(chunks):\n","    print(f\"Chunk {i + 1}: {chunk}\")"],"metadata":{"id":"-o85zLV2PnJK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754906195265,"user_tz":-330,"elapsed":3,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"7d57f89a-dfe4-42e1-b36d-37f961e40468"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunk 1: This is an example of\n","Chunk 2: example of overlapping chunking to\n","Chunk 3: chunking to maintain context between\n","Chunk 4: context between chunks.\n"]}]},{"cell_type":"markdown","source":["## **6. Recursive Chunking**\n","\n","Recursive chunking divides text in a hierarchical, iterative manner using a set of separators (such as newline characters or spaces). This method allows for more structured chunking based on content boundaries.\n","\n","**Explanation:**\n","\n","The method works by recursively splitting text into smaller chunks by examining separators like \\n\\n, \\n, and spaces.\n","LangChain offers the RecursiveCharacterTextSplitter class, which allows the specification of separators to control how the text is split."],"metadata":{"id":"Bmvff9fZPpcp"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","# Sample text\n","text = \"\"\"This is a paragraph \\n. This is another paragraph. This is a new paragraph.\n","\n","Here is some additional content.\\n\"\"\"\n","\n","# Initialize the RecursiveCharacterTextSplitter with separators\n","splitter = RecursiveCharacterTextSplitter(\n","    separators=[\"\\n\\n\", \"\\n\", \" \"],\n","    chunk_size=50,  # Adjust chunk size as necessary\n","    chunk_overlap=10  # Optional: overlap chunks for context preservation\n",")\n","\n","# Split the text\n","chunks = splitter.split_text(text)\n","\n","# Display chunks\n","for i, chunk in enumerate(chunks):\n","    print(f\"Chunk {i + 1}: {chunk}\")"],"metadata":{"id":"L78ccINUPp1V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754906198738,"user_tz":-330,"elapsed":13,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"8d2f119b-7a34-4629-ccbd-6baae741f090"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Chunk 1: This is a paragraph\n","Chunk 2: . This is another paragraph. This is a new\n","Chunk 3: is a new paragraph.\n","Chunk 4: Here is some additional content.\n"]}]},{"cell_type":"markdown","source":["## **7. Agentic Chunking**\n","\n","Agentic chunking leverages large language models (LLMs) to determine how to chunk the text based on its context. This is a more dynamic approach where the model itself decides how much and what part of the text should form a chunk.\n","\n","**Explanation:**\n","\n","The LLM is tasked with understanding the context of the text and then creating chunks based on the relevance of the information.\n","This technique uses the model's understanding of the content to ensure that chunks are informative and relevant."],"metadata":{"id":"gZof-EzvPsEv"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Load the tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n","\n","def chunk_text(text, max_length=512, stride=256):\n","    \"\"\"Chunks text into smaller pieces based on token length and stride.\n","\n","    Args:\n","        text (str): The input text.\n","        max_length (int, optional): Maximum token length of each chunk. Defaults to 512.\n","        stride (int, optional): Overlap between chunks. Defaults to 256.\n","\n","    Returns:\n","        list: A list of text chunks.\n","    \"\"\"\n","\n","    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids[0]\n","\n","    chunks = []\n","    i = 0\n","    while i < len(input_ids):\n","        end_idx = min(i + max_length, len(input_ids))\n","        chunk_ids = input_ids[i:end_idx]\n","        chunks.append(tokenizer.decode(chunk_ids, skip_special_tokens=True))\n","        i += stride\n","\n","    return chunks\n","\n","# Example usage\n","text = \"Astronauts travel through space. The journey is difficult. Exploration of Mars is a recent milestone in space science.\"\n","chunks = chunk_text(text)\n","\n","for chunk in chunks:\n","  print(chunk)"],"metadata":{"id":"V1PWN82LPsYX","colab":{"base_uri":"https://localhost:8080/","height":194,"referenced_widgets":["6eeb8bb57037413fa57be46238273d69","12edb559e01d48eba41f31d5c50fd208","b30d801656f34b1d9f66abdc8c8752ae","cc59eb710e7f498aa9ca069e33f9329a","0da0d050ed464d3f869ef9b3f394312f","44b6590f5ea4455196dff329fd71af96","513a06baa6154824a053fdde16450377","291643ea54f14ce18db9779c9e96ea7d","4784029c44f14e488301fba56398ba5b","ef2914dbe7ef454aae68fb3923f8efcb","40cf8d6b3dd2430cb0476a2c988cdcfb","e23e23ed601f4883b16a76e5492f851b","100b1efc353945c6a453cfb37881e908","84061250061f49bfacac8bf477468579","76a4835a35f1422a8d04cb57ae6267c0","74fadc62b2a146a8bdb556acdebd9017","985a68582c04495dbb9cc5c987923264","89ef26d347e8414cbb35e50d42134659","a55c3aea37524f329cf11276ebad7392","4351463426cf423dba22402424775586","5846ff1651a04560b55c2be0051c9296","23120697f1dc4823ada9b188d639ff67","0f1f23703b2c43ad8752c7d71cd1ca6b","7a098666ed084ea9a06fc84721c2f317","279f1ecfeee74642aeb0061e1416fccb","5e98b68c61ea4eda89054c8d08bdb46c","848f0e70210d4974b049dd243ac48080","ec7f12b22b6345d899ab37a0a109cc44","d1f7b13ef0b446cbb499aa205cf9ad0e","69ee8d425bc1469cb0f91bacbec3f349","ae376c5f0ec94c529652b6e9b9b3f70e","8a69d689c4be4373aea2eafebf44fbef","19f0c378487042b1bed1d60a0579fc18","f43c2282982b4fb1b77835b4aedd0d6f","f64ad0f2433f4bbf9618053eac64244c","e8253bd633e04823aeccc64896caa32c","cc0307043d2246d2abe7c6642ed895c4","9daa8044a50942f495c81bf71cf94111","3824ff21f9bf4202b378eb935c1bf989","05737b613c7f4d2ab2715b68b62beb6f","b3df0d4a331643d5a6be53916799154a","df91a8cd3c4942e78a51742e7efc8173","f891d63a0f424906889ac95573635748","e674330f585f48ab94f9a7076daf889c","7cae174c65b8497fa2b81db5e0ab1538","746304975ba44121ad515e7b31a30735","b8fc7a37051249808cf032843e80fe3e","3eff6d87d3b34781afb29511c2c9ba8c","0712b000505a44c982b56e99c9fe44ab","5ccee3724b1d4f36a5a8166d342f6368","58c5ffc0d53b44fbb8c9ba934091150d","6150cce7cf40424b8a12b3de5f33f2fa","991ada0373c44389a5c6383a2c5e3108","4300c3ab83ed4e919f9cd11608677e6a","7f3b63c9e3d34173a99454496e6d4624"]},"executionInfo":{"status":"ok","timestamp":1754906251849,"user_tz":-330,"elapsed":17710,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"8e20b5a4-26aa-4715-f64e-f61dbf988488"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eeb8bb57037413fa57be46238273d69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23e23ed601f4883b16a76e5492f851b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f1f23703b2c43ad8752c7d71cd1ca6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f43c2282982b4fb1b77835b4aedd0d6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cae174c65b8497fa2b81db5e0ab1538"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Astronauts travel through space. The journey is difficult. Exploration of Mars is a recent milestone in space science.\n"]}]},{"cell_type":"markdown","source":["## **8. Content-Aware Chunking**\n","\n","This method adapts chunking based on content characteristics (e.g., chunking text at paragraph level, tables as separate entities).\n","\n","**When to Use:**\n","\n","For documents with heterogeneous content, such as eBooks or technical manuals, chunking must vary based on content type."],"metadata":{"id":"D1sCdXysPu3e"}},{"cell_type":"code","source":["sample_text = \"\"\"\n","Introduction\n","\n","Data Science is an interdisciplinary field that uses scientific methods, processes,\n"," algorithms, and systems to extract knowledge and insights from structured and\n"," unstructured data. It draws from statistics, computer science, machine learning,\n"," and various data analysis techniques to discover patterns, make predictions, and\n"," derive actionable insights.\n","\n","Data Science can be applied across many industries, including healthcare, finance,\n"," marketing, and education, where it helps organizations make data-driven decisions,\n","  optimize processes, and understand customer behaviors.\n","\n","Overview of Big Data\n","\n","Big data refers to large, diverse sets of information that grow at ever-increasing\n","rates. It encompasses the volume of information, the velocity or speed at which it\n","is created and collected, and the variety or scope of the data points being\n","covered.\n","\n","Data Science Methods\n","\n","There are several important methods used in Data Science:\n","\n","1. Regression Analysis\n","2. Classification\n","3. Clustering\n","4. Neural Networks\n","\n","Challenges in Data Science\n","\n","- Data Quality: Poor data quality can lead to incorrect conclusions.\n","- Data Privacy: Ensuring the privacy of sensitive information.\n","- Scalability: Handling massive datasets efficiently.\n","\n","Conclusion\n","\n","Data Science continues to be a driving force in many industries, offering insights\n","that can lead to better decisions and optimized outcomes. It remains an evolving\n","field that incorporates the latest technological advancements.\n","\"\"\"\n","\n","\n","def content_aware_chunk(text):\n","    chunks = []\n","    current_chunk = []\n","    for line in text.splitlines():\n","        if line.startswith(('##', '###', 'Introduction', 'Conclusion')):\n","            if current_chunk:\n","                chunks.append('\\n'.join(current_chunk))\n","            current_chunk = [line]\n","        else:\n","            current_chunk.append(line)\n","    if current_chunk:\n","        chunks.append('\\n'.join(current_chunk))\n","    return chunks\n","\n","# Applying Content-Aware Chunking\n","content_chunks = content_aware_chunk(sample_text)\n","for chunk in content_chunks:\n","    print(chunk, '\\n---\\n')"],"metadata":{"id":"5Yq_UIlaPvXO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754914704628,"user_tz":-330,"elapsed":9,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"7289fa40-61aa-4647-da61-78bb25646dd9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","---\n","\n","Introduction\n","\n","Data Science is an interdisciplinary field that uses scientific methods, processes,\n"," algorithms, and systems to extract knowledge and insights from structured and\n"," unstructured data. It draws from statistics, computer science, machine learning,\n"," and various data analysis techniques to discover patterns, make predictions, and\n"," derive actionable insights.\n","\n","Data Science can be applied across many industries, including healthcare, finance,\n"," marketing, and education, where it helps organizations make data-driven decisions,\n","  optimize processes, and understand customer behaviors.\n","\n","Overview of Big Data\n","\n","Big data refers to large, diverse sets of information that grow at ever-increasing\n","rates. It encompasses the volume of information, the velocity or speed at which it\n","is created and collected, and the variety or scope of the data points being\n","covered.\n","\n","Data Science Methods\n","\n","There are several important methods used in Data Science:\n","\n","1. Regression Analysis\n","2. Classification\n","3. Clustering\n","4. Neural Networks\n","\n","Challenges in Data Science\n","\n","- Data Quality: Poor data quality can lead to incorrect conclusions.\n","- Data Privacy: Ensuring the privacy of sensitive information.\n","- Scalability: Handling massive datasets efficiently.\n"," \n","---\n","\n","Conclusion\n","\n","Data Science continues to be a driving force in many industries, offering insights\n","that can lead to better decisions and optimized outcomes. It remains an evolving\n","field that incorporates the latest technological advancements. \n","---\n","\n"]}]},{"cell_type":"markdown","source":["## **9. Token-Based Chunking**\n","\n","Token-based chunking splits text based on a fixed number of tokens rather than words or sentences. It uses tokenizers from NLP models (e.g., Hugging Face’s transformers).\n","\n","**When to Use:**\n","\n","For models that operate on tokens, such as transformer-based models with token limits (e.g., GPT-3 or GPT-4).\n","\n","Advantages:\n","- Works well with transformer-based models.\n","- Ensures token limits are respected.\n","\n","Disadvantages:\n","- Tokenization may split sentences or break context.\n","- Not always aligned with natural language boundaries.\n"],"metadata":{"id":"fE7GpjgRPx_Q"}},{"cell_type":"code","source":["from transformers import GPT2Tokenizer\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","def token_based_chunk(text, max_tokens=200):\n","    tokens = tokenizer(text)[\"input_ids\"]\n","    chunks = [tokens[i:i + max_tokens] for i in range(0, len(tokens), max_tokens)]\n","    return [tokenizer.decode(chunk) for chunk in chunks]\n","\n","# Applying Token-Based Chunking\n","token_chunks = token_based_chunk(sample_text)\n","for chunk in token_chunks:\n","    print(chunk, '\\n---\\n')"],"metadata":{"id":"v45LYIY_PyYk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754906723607,"user_tz":-330,"elapsed":518,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"80aae9a9-174e-4d0b-d382-bddb8ae11e0c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Introduction\n","\n","Data Science is an interdisciplinary field that uses scientific methods, processes,\n"," algorithms, and systems to extract knowledge and insights from structured and\n"," unstructured data. It draws from statistics, computer science, machine learning,\n"," and various data analysis techniques to discover patterns, make predictions, and\n"," derive actionable insights.\n","\n","Data Science can be applied across many industries, including healthcare, finance,\n"," marketing, and education, where it helps organizations make data-driven decisions,\n","  optimize processes, and understand customer behaviors.\n","\n","Overview of Big Data\n","\n","Big data refers to large, diverse sets of information that grow at ever-increasing\n","rates. It encompasses the volume of information, the velocity or speed at which it\n","is created and collected, and the variety or scope of the data points being\n","covered.\n","\n","Data Science Methods\n","\n","There are several important methods used in Data Science:\n","\n","1. Regression Analysis\n","2. Classification\n","3 \n","---\n","\n",". Clustering\n","4. Neural Networks\n","\n","Challenges in Data Science\n","\n","- Data Quality: Poor data quality can lead to incorrect conclusions.\n","- Data Privacy: Ensuring the privacy of sensitive information.\n","- Scalability: Handling massive datasets efficiently.\n","\n","Conclusion\n","\n","Data Science continues to be a driving force in many industries, offering insights\n","that can lead to better decisions and optimized outcomes. It remains an evolving\n","field that incorporates the latest technological advancements.\n"," \n","---\n","\n"]}]},{"cell_type":"markdown","source":["## **10. Topic-Based Chunking**\n","This strategy splits the document based on topics using techniques like Latent Dirichlet Allocation (LDA) or other topic modeling algorithms to segment the text.\n","\n","**When to Use:**\n","\n","For documents that cover multiple topics, such as news articles, research papers, or reports with diverse subject matter.\n","\n","Advantages:\n","- Groups related information together.\n","- Helps in focused retrieval based on specific topics.\n","\n","Disadvantages:\n","- Requires additional processing (topic modeling).\n","- May not be precise for short documents or overlapping topics."],"metadata":{"id":"We9D7L7kPz7g"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","import numpy as np\n","\n","def topic_based_chunk(text, num_topics=3):\n","    # Split the text into sentences for chunking\n","    sentences = text.split('. ')\n","\n","    # Vectorize the sentences\n","    vectorizer = CountVectorizer()\n","    sentence_vectors = vectorizer.fit_transform(sentences)\n","\n","    # Apply LDA for topic modeling\n","    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n","    lda.fit(sentence_vectors)\n","\n","    # Get the topic-word distribution\n","    topic_word = lda.components_\n","    vocabulary = vectorizer.get_feature_names_out()\n","\n","    # Identify the top words for each topic\n","    topics = []\n","    for topic_idx, topic in enumerate(topic_word):\n","        top_words_idx = topic.argsort()[:-6:-1]\n","        topic_keywords = [vocabulary[i] for i in top_words_idx]\n","        topics.append(\"Topic {}: {}\".format(topic_idx + 1, ', '.join(topic_keywords)))\n","\n","    # Generate chunks with topics\n","    chunks_with_topics = []\n","    for i, sentence in enumerate(sentences):\n","        topic_assignments = lda.transform(vectorizer.transform([sentence]))\n","        assigned_topic = np.argmax(topic_assignments)\n","        chunks_with_topics.append((topics[assigned_topic], sentence))\n","\n","    return chunks_with_topics\n","\n","\n","# Get topic-based chunks\n","topic_chunks = topic_based_chunk(sample_text, num_topics=3)\n","\n","# Display results\n","for topic, chunk in topic_chunks:\n","    print(f\"{topic}: {chunk}\\n\")"],"metadata":{"id":"AJ9nCgxoP1o7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754914709529,"user_tz":-330,"elapsed":60,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"ef401b91-7cca-4563-ac95-3edd449afe1f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Topic 2: data, and, to, science, that: \n","Introduction\n","\n","Data Science is an interdisciplinary field that uses scientific methods, processes,\n"," algorithms, and systems to extract knowledge and insights from structured and\n"," unstructured data\n","\n","Topic 2: data, and, to, science, that: It draws from statistics, computer science, machine learning,\n"," and various data analysis techniques to discover patterns, make predictions, and\n"," derive actionable insights.\n","\n","Data Science can be applied across many industries, including healthcare, finance,\n"," marketing, and education, where it helps organizations make data-driven decisions,\n","  optimize processes, and understand customer behaviors.\n","\n","Overview of Big Data\n","\n","Big data refers to large, diverse sets of information that grow at ever-increasing\n","rates\n","\n","Topic 3: the, it, data, methods, of: It encompasses the volume of information, the velocity or speed at which it\n","is created and collected, and the variety or scope of the data points being\n","covered.\n","\n","Data Science Methods\n","\n","There are several important methods used in Data Science:\n","\n","1\n","\n","Topic 3: the, it, data, methods, of: Regression Analysis\n","2\n","\n","Topic 2: data, and, to, science, that: Classification\n","3\n","\n","Topic 1: clustering, classification, analysis, regression, field: Clustering\n","4\n","\n","Topic 2: data, and, to, science, that: Neural Networks\n","\n","Challenges in Data Science\n","\n","- Data Quality: Poor data quality can lead to incorrect conclusions.\n","- Data Privacy: Ensuring the privacy of sensitive information.\n","- Scalability: Handling massive datasets efficiently.\n","\n","Conclusion\n","\n","Data Science continues to be a driving force in many industries, offering insights\n","that can lead to better decisions and optimized outcomes\n","\n","Topic 3: the, it, data, methods, of: It remains an evolving\n","field that incorporates the latest technological advancements.\n","\n","\n"]}]},{"cell_type":"markdown","source":["## **11. Keyword-Based Chunking**\n","\n","This method chunks documents based on predefined keywords or phrases that signal topic shifts (e.g., “Introduction,” “Conclusion”).\n","\n","**When to Use:**\n","\n","Best for documents that follow a clear structure, such as scientific papers or technical specifications.\n","\n","Advantages:\n","- Captures natural topic breaks based on keywords.\n","- Works well for structured documents.\n","\n","Disadvantages:\n","- Requires a predefined set of keywords.\n","- Not adaptable to unstructured text."],"metadata":{"id":"_Gyp2UjvP3Lr"}},{"cell_type":"code","source":["def keyword_based_chunk(text, keywords):\n","    chunks = []\n","    current_chunk = []\n","    for line in text.splitlines():\n","        if any(keyword in line for keyword in keywords):\n","            if current_chunk:\n","                chunks.append('\\n'.join(current_chunk))\n","            current_chunk = [line]\n","        else:\n","            current_chunk.append(line)\n","    if current_chunk:\n","        chunks.append('\\n'.join(current_chunk))\n","    return chunks\n","\n","# Applying Keyword-Based Chunking\n","keywords = [\"Introduction\", \"Overview\", \"Conclusion\", \"Methods\", \"Challenges\"]\n","keyword_chunks = keyword_based_chunk(sample_text, keywords)\n","for chunk in keyword_chunks:\n","    print(chunk, '\\n---\\n')"],"metadata":{"id":"2E4PoQUXP5MC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754914714710,"user_tz":-330,"elapsed":17,"user":{"displayName":"Jai Ganesh (JAISH)","userId":"04818989293263783952"}},"outputId":"3c580696-1d0b-40eb-fafc-e2fd8dde3bcd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","---\n","\n","Introduction\n","\n","Data Science is an interdisciplinary field that uses scientific methods, processes,\n"," algorithms, and systems to extract knowledge and insights from structured and\n"," unstructured data. It draws from statistics, computer science, machine learning,\n"," and various data analysis techniques to discover patterns, make predictions, and\n"," derive actionable insights.\n","\n","Data Science can be applied across many industries, including healthcare, finance,\n"," marketing, and education, where it helps organizations make data-driven decisions,\n","  optimize processes, and understand customer behaviors.\n"," \n","---\n","\n","Overview of Big Data\n","\n","Big data refers to large, diverse sets of information that grow at ever-increasing\n","rates. It encompasses the volume of information, the velocity or speed at which it\n","is created and collected, and the variety or scope of the data points being\n","covered.\n"," \n","---\n","\n","Data Science Methods\n","\n","There are several important methods used in Data Science:\n","\n","1. Regression Analysis\n","2. Classification\n","3. Clustering\n","4. Neural Networks\n"," \n","---\n","\n","Challenges in Data Science\n","\n","- Data Quality: Poor data quality can lead to incorrect conclusions.\n","- Data Privacy: Ensuring the privacy of sensitive information.\n","- Scalability: Handling massive datasets efficiently.\n"," \n","---\n","\n","Conclusion\n","\n","Data Science continues to be a driving force in many industries, offering insights\n","that can lead to better decisions and optimized outcomes. It remains an evolving\n","field that incorporates the latest technological advancements. \n","---\n","\n"]}]},{"cell_type":"markdown","source":["### **Trade-offs Between Chunk Size, Retrieval Speed, and Accuracy**\n","\n","**Larger Chunks:**\n","- Pros: More context, better accuracy.\n","- Cons: Slower retrieval, higher memory usage.\n","\n","**Smaller Chunks:**\n","- Pros: Faster retrieval, lower memory usage.\n","- Cons: Less context, potential loss of accuracy.\n","\n","### **Optimization Tactics:**\n","\n","**Sliding Window Chunking: Combines the best of both worlds:**\n","- Preserves context by overlapping chunks.\n","- Maintains reasonable retrieval speed.\n","\n","**Token-Based Chunking:**\n","- Ensures chunks fit within model token limits.\n","- Maintains efficient retrieval."],"metadata":{"id":"T8qmKcOrP7xZ"}},{"cell_type":"code","source":[],"metadata":{"id":"HEJkzqotP80v"},"execution_count":null,"outputs":[]}]}